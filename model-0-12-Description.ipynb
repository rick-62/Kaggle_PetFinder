{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 0.12 - Description\n",
    "- Removed Tfidf, as results were disappointing\n",
    "- Added basic description counts\n",
    "- Insignficant on top of existing model\n",
    "- When breeds removed, became fairly significant (~1%)\n",
    "- Running this on LB reduces the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ml_metrics\n",
    "import string\n",
    "import nltk\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hides warnings - think it needs running after modules imported\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = 42  # random state for scoring consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/train/train.csv\", index_col=\"PetID\")\n",
    "df_test = pd.read_csv(\"../input/test/test.csv\", index_col=\"PetID\")\n",
    "df_breeds = pd.read_csv(\"../input/breed_labels.csv\", index_col=\"BreedID\")\n",
    "df_colors = pd.read_csv(\"../input/color_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = df_colors['ColorID']\n",
    "breeds = df_breeds.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "3076eefcc83e005977b9159c9d39459e5d08e27a"
   },
   "outputs": [],
   "source": [
    "def apply_word_flags(df, words, drop=True):\n",
    "    \"\"\"Creates binary columns for words which appear in the description\"\"\"\n",
    "    for word in words:\n",
    "        df[word] = 0\n",
    "    for i, desc in df['Description'].items():\n",
    "        try:\n",
    "            for word in desc.split():\n",
    "                word = word.lower()\n",
    "                if word in words:\n",
    "                    df.at[i,word] = 1\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    return df.drop(columns=['Description'] if drop else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['home', 'good' , 'adopt', 'loving', 'give', 'looking', 'playful', 'rescued', 'cat', 'contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_flags(df, colors):\n",
    "    \"\"\"Combines Colors 1,2 & 3 into binary columns for each possible colours\"\"\"\n",
    "    for c in colors:\n",
    "        df[f'C{c}'] = 0\n",
    "    for i,colors in df[['Color1', 'Color2', 'Color3']].iterrows():\n",
    "        for c in colors:\n",
    "            if c != 0:\n",
    "                df.at[i,f'C{c}'] = 1\n",
    "    df = df.drop(columns=['Color1', 'Color2', 'Color3'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_breed_keywords(df):\n",
    "    \"\"\"Creates unique list of keywords from provided breeds dataframe\"\"\"\n",
    "    breed_keywords = []\n",
    "    for breed in df['BreedName']:\n",
    "        breed = re.sub(r'[/(/)]', '', breed)  # remove braces\n",
    "        keywords = breed.split()\n",
    "        breed_keywords += keywords\n",
    "    return set(breed_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_breed_flags(df, keywords, breeds):\n",
    "    \"\"\"Creates binary columns for keywords which appear in the breed name\"\"\"\n",
    "    for word in keywords:\n",
    "        df[word] = 0\n",
    "        \n",
    "    for i,pair in df[['Breed1', 'Breed2']].iterrows():\n",
    "        for indx in pair:\n",
    "            if indx == 0: continue\n",
    "            breed = breeds.loc[indx,'BreedName']\n",
    "            breed = re.sub(r'[/(/)]', '', breed)\n",
    "            new_keywords = breed.split()\n",
    "            for word in new_keywords:\n",
    "                if word in keywords: \n",
    "                    df.at[i,word] = 1\n",
    "                    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and training data\n",
    "df_combined = pd.concat([df_test, df_train], sort=False)\n",
    "df_combined['test'] = df_combined['AdoptionSpeed'].isna()\n",
    "\n",
    "# Rescuer\n",
    "rescue_map = Counter(df_combined['RescuerID'])\n",
    "rescuer_counts = df_combined['RescuerID'].map(rescue_map)\n",
    "\n",
    "# Breeds\n",
    "all_test_breeds = df_test['Breed1'].append(df_test['Breed2'])\n",
    "df_test_breeds = df_breeds.loc[all_test_breeds[all_test_breeds > 0].unique(), :]\n",
    "breed_keywords = create_breed_keywords(df_test_breeds)\n",
    "\n",
    "# Prepare data for modelling \n",
    "df_combined['rescuer_counts'] = rescuer_counts\n",
    "df_combined = apply_word_flags(df_combined, keywords, drop=False)\n",
    "df_combined = apply_color_flags(df_combined, colors)\n",
    "df_combined = apply_breed_flags(df_combined, breed_keywords, df_breeds)\n",
    "df_combined = pd.get_dummies(df_combined, columns=['Gender',\n",
    "                                                   'Vaccinated', 'Dewormed', 'Sterilized', \n",
    "                                                   'State'])\n",
    "y_train_all = df_combined['AdoptionSpeed'][df_combined['test'] != 1]\n",
    "X_all       = df_combined.drop(columns=['Name', 'RescuerID', 'AdoptionSpeed', 'Breed1', 'Breed2'])\n",
    "X_train_all = X_all[X_all['test'] != 1].drop(columns=['test'])\n",
    "X_test_all  = X_all[X_all['test'] == 1].drop(columns=['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all missing descriptions with a string length 0\n",
    "X_train_all['Description'] = X_train_all['Description'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of Description characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with length of description\n",
    "X_train_all['desc_length'] = X_train_all['Description'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of Description words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and count words in description\n",
    "X_train_all['desc_word_count'] = X_train_all['Description'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove description feature\n",
    "X_train_all = X_train_all.drop(columns=['Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Counts to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all['Description'] = X_test_all['Description'].fillna('')\n",
    "X_test_all['desc_length'] = X_test_all['Description'].apply(len)\n",
    "X_test_all['desc_word_count'] = X_test_all['Description'].apply(lambda x: len(x.split()))\n",
    "X_test_all = X_test_all.drop(columns=['Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 4, \n",
    "          'learning_rate': 0.2, \n",
    "          'n_estimators': 200, \n",
    "          'silent': True, \n",
    "          'objective': 'multi:softprob', \n",
    "          'booster': 'gbtree',\n",
    "          'tree_method': 'hist',\n",
    "          'n_jobs': 3,\n",
    "          'gamma': 0, \n",
    "          'min_child_weight': 1, \n",
    "          'max_delta_step': 0, \n",
    "          'subsample': 0.8, \n",
    "          'colsample_bytree': 1, \n",
    "          'colsample_bylevel': 1, \n",
    "          'reg_alpha': 0, \n",
    "          'reg_lambda': 1, \n",
    "          'scale_pos_weight': 1, \n",
    "          'base_score': 0.2, \n",
    "          'random_state': rnd, \n",
    "          'missing': None,\n",
    "          'verbose': 0,\n",
    "          'verbosity': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cv_testing(X_train_all, params, folds=5, dataframe=True):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    folds = KFold(folds, True, rnd).split(X_train_all)\n",
    "\n",
    "    for train_indx, test_indx in folds:\n",
    "\n",
    "        # flag dataframe determines whether to use iloc or \"normal\" masking for (sparse) arrays\n",
    "        if not dataframe:\n",
    "            X_train, X_test = X_train_all[train_indx], X_train_all[test_indx]\n",
    "            y_train, y_test = y_train_all[train_indx], y_train_all[test_indx]\n",
    "        else:\n",
    "            X_train, X_test = X_train_all.iloc[train_indx], X_train_all.iloc[test_indx]\n",
    "            y_train, y_test = y_train_all.iloc[train_indx], y_train_all.iloc[test_indx]\n",
    "\n",
    "\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        prediction = clf.predict(X_test)\n",
    "\n",
    "        scores.append(ml_metrics.quadratic_weighted_kappa(rater_a=y_test, rater_b=prediction))\n",
    "        print(\"{:.3f}\".format(scores[-1]), end=\"\\t\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:20] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.396\t[22:05:28] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.428\t[22:05:37] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.408\t[22:05:45] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.392\t[22:05:53] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.373\t[22:06:02] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.393\t[22:06:10] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.390\t[22:06:18] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.378\t[22:06:27] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.376\t[22:06:35] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.352\t\n"
     ]
    }
   ],
   "source": [
    "scores = cv_testing(X_train_all=X_train_all, folds=10, params=params, dataframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38858164531908523"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.390 --> 0.389 (new initialised score)\n",
    "# 0.389 --> 0.388 (count of description - insignificant)\n",
    "# 0.389 --> 0.385 (count of description words - insignificant)\n",
    "# 0.389 --> 0.388 (count of chars and words - insignificant)\n",
    "# 0.389 --> 0.339 (remove breeds)\n",
    "# 0.339 --> 0.351 (add counts - significant increase)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:10:52] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(**params)\n",
    "clf.fit(X_train_all, y_train_all)\n",
    "prediction = clf.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'AdoptionSpeed': prediction.astype(int)}, index=X_test_all.index)\n",
    "submission.to_csv(\"submission.csv\", index=True, index_label='PetID', header=['AdoptionSpeed'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
