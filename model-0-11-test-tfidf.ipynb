{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 0.11 - Test Tfidf\n",
    "- Cleanup Tfidf, after previous experitmentation and play about with tfidf and sparse arrays\n",
    "- Reduced features for testing and using dense, instead of sparse\n",
    "- \"Trained\" Tfidf on all data, not just test or training corpus\n",
    "- Tried top 100, 10 and 5 features: no improvement/worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ml_metrics\n",
    "import string\n",
    "import nltk\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hides warnings - think it needs running after modules imported\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = 42  # random state for scoring consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/train/train.csv\", index_col=\"PetID\")\n",
    "df_test = pd.read_csv(\"../input/test/test.csv\", index_col=\"PetID\")\n",
    "df_breeds = pd.read_csv(\"../input/breed_labels.csv\", index_col=\"BreedID\")\n",
    "df_colors = pd.read_csv(\"../input/color_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = df_colors['ColorID']\n",
    "breeds = df_breeds.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "3076eefcc83e005977b9159c9d39459e5d08e27a"
   },
   "outputs": [],
   "source": [
    "def apply_word_flags(df, words):\n",
    "    \"\"\"Creates binary columns for words which appear in the description\"\"\"\n",
    "    for word in words:\n",
    "        df[word] = 0\n",
    "    for i, desc in df['Description'].items():\n",
    "        try:\n",
    "            for word in desc.split():\n",
    "                word = word.lower()\n",
    "                if word in words:\n",
    "                    df.at[i,word] = 1\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    return df.drop(columns=['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['home', 'good' , 'adopt', 'loving', 'give', 'looking', 'playful', 'rescued', 'cat', 'contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_flags(df, colors):\n",
    "    \"\"\"Combines Colors 1,2 & 3 into binary columns for each possible colours\"\"\"\n",
    "    for c in colors:\n",
    "        df[f'C{c}'] = 0\n",
    "    for i,colors in df[['Color1', 'Color2', 'Color3']].iterrows():\n",
    "        for c in colors:\n",
    "            if c != 0:\n",
    "                df.at[i,f'C{c}'] = 1\n",
    "    df = df.drop(columns=['Color1', 'Color2', 'Color3'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_breed_keywords(df):\n",
    "    \"\"\"Creates unique list of keywords from provided breeds dataframe\"\"\"\n",
    "    breed_keywords = []\n",
    "    for breed in df['BreedName']:\n",
    "        breed = re.sub(r'[/(/)]', '', breed)  # remove braces\n",
    "        keywords = breed.split()\n",
    "        breed_keywords += keywords\n",
    "    return set(breed_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_breed_flags(df, keywords, breeds):\n",
    "    \"\"\"Creates binary columns for keywords which appear in the breed name\"\"\"\n",
    "    for word in keywords:\n",
    "        df[word] = 0\n",
    "        \n",
    "    for i,pair in df[['Breed1', 'Breed2']].iterrows():\n",
    "        for indx in pair:\n",
    "            if indx == 0: continue\n",
    "            breed = breeds.loc[indx,'BreedName']\n",
    "            breed = re.sub(r'[/(/)]', '', breed)\n",
    "            new_keywords = breed.split()\n",
    "            for word in new_keywords:\n",
    "                if word in keywords: \n",
    "                    df.at[i,word] = 1\n",
    "                    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer for description, to return list of word tokens\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and training data\n",
    "df_combined = pd.concat([df_test, df_train], sort=False)\n",
    "df_combined['test'] = df_combined['AdoptionSpeed'].isna()\n",
    "\n",
    "# Rescuer\n",
    "rescue_map = Counter(df_combined['RescuerID'])\n",
    "rescuer_counts = df_combined['RescuerID'].map(rescue_map)\n",
    "\n",
    "# Breeds\n",
    "all_test_breeds = df_test['Breed1'].append(df_test['Breed2'])\n",
    "df_test_breeds = df_breeds.loc[all_test_breeds[all_test_breeds > 0].unique(), :]\n",
    "breed_keywords = create_breed_keywords(df_test_breeds)\n",
    "\n",
    "# Prepare data for modelling \n",
    "df_combined['rescuer_counts'] = rescuer_counts\n",
    "# df_combined = apply_word_flags(df_combined, keywords)\n",
    "df_combined = apply_color_flags(df_combined, colors)\n",
    "df_combined = apply_breed_flags(df_combined, breed_keywords, df_breeds)\n",
    "df_combined = pd.get_dummies(df_combined, columns=['Gender',\n",
    "                                                   'Vaccinated', 'Dewormed', 'Sterilized', \n",
    "                                                   'State'])\n",
    "y_train_all = df_combined['AdoptionSpeed'][df_combined['test'] != 1]\n",
    "X_all       = df_combined.drop(columns=['Name', 'RescuerID', 'AdoptionSpeed', 'Breed1', 'Breed2'])\n",
    "X_train_all = X_all[X_all['test'] != 1].drop(columns=['test'])\n",
    "X_test_all  = X_all[X_all['test'] == 1].drop(columns=['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation from text\n",
    "remove_punc = str.maketrans({key: None for key in string.punctuation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of all test data descriptions\n",
    "token_dict = {}\n",
    "for idx, desc in df_combined['Description'].items():\n",
    "    try:\n",
    "        token_dict[idx] = desc.translate(remove_punc).lower()\n",
    "    except AttributeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Tfidf\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english', max_features=5)\n",
    "tfs = tfidf.fit_transform(token_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training features count\n",
    "features = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace np.nan with blank text\n",
    "df_combined['Description'] = df_combined['Description'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all data to test data tokens\n",
    "response = tfidf.transform(df_combined['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert response to array (if becomes issue will use sparse array but might need to convert rest of data)\n",
    "response_arr = response.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all data to test data tokens\n",
    "response = tfidf.transform(X_all['Description'].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features for checking\n",
    "features = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bouncer is a happy pup that needs a happy loving environment to grow up in and of course till its last day in this world. If you can do that for him please call or whatsapp Jocelyn at. Adoption requirement is commit to neutering. I collect back vaccination fee. Please Don't sms or email.\n",
      "\n",
      "love \t 0.761\n",
      "adopt \t 0.649\n"
     ]
    }
   ],
   "source": [
    "# check sample rows\n",
    "print(X_all.iloc[4000]['Description'], end='\\n\\n')\n",
    "values = []\n",
    "for row, col in zip(response.nonzero()[0], response.nonzero()[1]):\n",
    "    if row == 4000: \n",
    "        values.append(response[0, col])\n",
    "        print(\"{} \\t {:.3f}\".format(features[col], response[row, col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features\n",
    "tfidf_features = features.copy()\n",
    "features = list(X_all.drop(columns=['test','Description']).columns)\n",
    "features.extend(tfidf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for tfidf and combine with original data\n",
    "df_response = pd.DataFrame(columns = tfidf_features,\n",
    "                           data = response.todense(),\n",
    "                           index = X_all.index)\n",
    "result = pd.concat([df_response, X_all], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowball... doesn't look so good (she is healthy)... a bit cranky but still... she is for adoption... She is actually a very manja and gentle cat. May be she doesn't like her photo to be taken...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "adopt                                                      0.466757\n",
       "cat                                                        0.683185\n",
       "home                                                              0\n",
       "love                                                              0\n",
       "veri                                                       0.561601\n",
       "Type                                                              2\n",
       "Age                                                              20\n",
       "MaturitySize                                                      2\n",
       "FurLength                                                         1\n",
       "Health                                                            1\n",
       "Quantity                                                          1\n",
       "Fee                                                             150\n",
       "VideoAmt                                                          0\n",
       "Description       Snowball... doesn't look so good (she is healt...\n",
       "PhotoAmt                                                          1\n",
       "test                                                           True\n",
       "rescuer_counts                                                  146\n",
       "C1                                                                0\n",
       "C2                                                                0\n",
       "C3                                                                0\n",
       "Name: 72000c4c5, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check sample rows\n",
    "print(df_combined.iloc[2]['Description'])\n",
    "result.iloc[2][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and test data ready for testing model\n",
    "X_train_df = result[result['test'] != 1].drop(columns=['test', 'Description'])\n",
    "X_test_df = result[result['test'] == 1].drop(columns=['test', 'Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 4, \n",
    "          'learning_rate': 0.2, \n",
    "          'n_estimators': 200, \n",
    "          'silent': True, \n",
    "          'objective': 'multi:softprob', \n",
    "          'booster': 'gbtree',\n",
    "          'tree_method': 'hist',\n",
    "          'n_jobs': 3,\n",
    "          'gamma': 0, \n",
    "          'min_child_weight': 1, \n",
    "          'max_delta_step': 0, \n",
    "          'subsample': 0.8, \n",
    "          'colsample_bytree': 1, \n",
    "          'colsample_bylevel': 1, \n",
    "          'reg_alpha': 0, \n",
    "          'reg_lambda': 1, \n",
    "          'scale_pos_weight': 1, \n",
    "          'base_score': 0.2, \n",
    "          'random_state': rnd, \n",
    "          'missing': None,\n",
    "          'verbose': 0,\n",
    "          'verbosity': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cv_testing(X_train_all, params, folds=5, dataframe=True):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    folds = KFold(folds, True, rnd).split(X_train_all)\n",
    "\n",
    "    for train_indx, test_indx in folds:\n",
    "\n",
    "        # flag dataframe determines whether to use iloc or \"normal\" masking for (sparse) arrays\n",
    "        if not dataframe:\n",
    "            X_train, X_test = X_train_all[train_indx], X_train_all[test_indx]\n",
    "            y_train, y_test = y_train_all[train_indx], y_train_all[test_indx]\n",
    "        else:\n",
    "            X_train, X_test = X_train_all.iloc[train_indx], X_train_all.iloc[test_indx]\n",
    "            y_train, y_test = y_train_all.iloc[train_indx], y_train_all.iloc[test_indx]\n",
    "\n",
    "\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        prediction = clf.predict(X_test)\n",
    "\n",
    "        scores.append(ml_metrics.quadratic_weighted_kappa(rater_a=y_test, rater_b=prediction))\n",
    "        print(\"{:.3f}\".format(scores[-1]), end=\"\\t\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:15:06] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.391\t[09:15:14] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.418\t[09:15:22] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.391\t[09:15:31] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.377\t[09:15:39] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.366\t[09:15:47] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.409\t[09:15:55] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.373\t[09:16:03] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.390\t[09:16:11] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.357\t[09:16:19] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.359\t\n"
     ]
    }
   ],
   "source": [
    "scores = cv_testing(X_train_all=X_train_df, folds=10, params=params, dataframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.383182483471643"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.390 --> 0.382 (dense dataframe of tfidf (all data) - 10 features)\n",
    "# 0.390 --> 0.371 (dense dataframe of tfidf (all data) - 100 features)\n",
    "# 0.390 --> 0.383 (dense dataframe of tfidf (all data) - 5 features)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = xgb.XGBClassifier(**params)\n",
    "# clf.fit(X_train_all, y_train_all)\n",
    "# prediction = clf.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'AdoptionSpeed': prediction.astype(int)}, index=X_test_all.index)\n",
    "# submission.to_csv(\"submission.csv\", index=True, index_label='PetID', header=['AdoptionSpeed'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
