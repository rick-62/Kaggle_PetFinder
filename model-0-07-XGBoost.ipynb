{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 0.07 - XGBoost\n",
    "- XGBoost implementation, with no optimization, just a straight swap for random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import ml_metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = 42  # random state for scoring consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/train/train.csv\", index_col=\"PetID\")\n",
    "df_test = pd.read_csv(\"../input/test/test.csv\", index_col=\"PetID\")\n",
    "df_breeds = pd.read_csv(\"../input/breed_labels.csv\", index_col=\"BreedID\")\n",
    "df_colors = pd.read_csv(\"../input/color_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = df_colors['ColorID']\n",
    "breeds = df_breeds.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "3076eefcc83e005977b9159c9d39459e5d08e27a"
   },
   "outputs": [],
   "source": [
    "def apply_word_flags(df, words):\n",
    "    \"\"\"Creates binary columns for words which appear in the description\"\"\"\n",
    "    for word in words:\n",
    "        df[word] = 0\n",
    "    for i, desc in df['Description'].items():\n",
    "        try:\n",
    "            for word in desc.split():\n",
    "                word = word.lower()\n",
    "                if word in words:\n",
    "                    df.at[i,word] = 1\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    return df.drop(columns=['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['home', 'good' , 'adopt', 'loving', 'give', 'looking', 'playful', 'rescued', 'cat', 'contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_flags(df, colors):\n",
    "    \"\"\"Combines Colors 1,2 & 3 into binary columns for each possible colours\"\"\"\n",
    "    for c in colors:\n",
    "        df[f'C{c}'] = 0\n",
    "    for i,colors in df[['Color1', 'Color2', 'Color3']].iterrows():\n",
    "        for c in colors:\n",
    "            if c != 0:\n",
    "                df.at[i,f'C{c}'] = 1\n",
    "    df = df.drop(columns=['Color1', 'Color2', 'Color3'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_breed_keywords(df):\n",
    "    \"\"\"Creates unique list of keywords from provided breeds dataframe\"\"\"\n",
    "    breed_keywords = []\n",
    "    for breed in df['BreedName']:\n",
    "        breed = re.sub(r'[/(/)]', '', breed)  # remove braces\n",
    "        keywords = breed.split()\n",
    "        breed_keywords += keywords\n",
    "    return set(breed_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_breed_flags(df, keywords, breeds):\n",
    "    \"\"\"Creates binary columns for keywords which appear in the breed name\"\"\"\n",
    "    for word in keywords:\n",
    "        df[word] = 0\n",
    "        \n",
    "    for i,pair in df[['Breed1', 'Breed2']].iterrows():\n",
    "        for indx in pair:\n",
    "            if indx == 0: continue\n",
    "            breed = breeds.loc[indx,'BreedName']\n",
    "            breed = re.sub(r'[/(/)]', '', breed)\n",
    "            new_keywords = breed.split()\n",
    "            for word in new_keywords:\n",
    "                if word in keywords: \n",
    "                    df.at[i,word] = 1\n",
    "                    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and training data\n",
    "df_combined = pd.concat([df_test, df_train], sort=False)\n",
    "df_combined['test'] = df_combined['AdoptionSpeed'].isna()\n",
    "\n",
    "# Rescuer\n",
    "rescue_map = Counter(df_combined['RescuerID'])\n",
    "rescuer_counts = df_combined['RescuerID'].map(rescue_map)\n",
    "\n",
    "# Breeds\n",
    "all_test_breeds = df_test['Breed1'].append(df_test['Breed2'])\n",
    "df_test_breeds = df_breeds.loc[all_test_breeds[all_test_breeds > 0].unique(), :]\n",
    "breed_keywords = create_breed_keywords(df_test_breeds)\n",
    "\n",
    "# Prepare data for modelling \n",
    "df_combined['rescuer_counts'] = rescuer_counts\n",
    "df_combined = apply_word_flags(df_combined, keywords)\n",
    "df_combined = apply_color_flags(df_combined, colors)\n",
    "df_combined = apply_breed_flags(df_combined, breed_keywords, df_breeds)\n",
    "df_combined = pd.get_dummies(df_combined, columns=['Gender',\n",
    "                                                   'Vaccinated', 'Dewormed', 'Sterilized', \n",
    "                                                   'State'])\n",
    "y_train_all = df_combined['AdoptionSpeed'][df_combined['test'] != 1]\n",
    "X_all       = df_combined.drop(columns=['Name', 'RescuerID', 'AdoptionSpeed', 'Breed1', 'Breed2'])\n",
    "X_train_all = X_all[X_all['test'] != 1].drop(columns=['test'])\n",
    "X_test_all  = X_all[X_all['test'] == 1].drop(columns=['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3906629511777221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4087257628261515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40331844586398835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37194599470880296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35298087388724286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39605147471504654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3747194641912931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36914830674019383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.362481894458231\n",
      "0.3569417039313474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "folds = KFold(10, True, rnd).split(X_train_all)\n",
    "\n",
    "for train_indx, test_indx in folds:\n",
    "    \n",
    "    X_train, X_test = X_train_all.iloc[train_indx], X_train_all.iloc[test_indx]\n",
    "    y_train, y_test = y_train_all.iloc[train_indx], y_train_all.iloc[test_indx]\n",
    "    \n",
    "    xgb = XGBClassifier(n_estimators=200, seed=rnd)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    prediction = xgb.predict(X_test)\n",
    "    scores.append(ml_metrics.quadratic_weighted_kappa(rater_a=y_test, rater_b=prediction))\n",
    "    print(scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37869768725000197"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.394 --> 0.367 (LB 0.317)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = RandomForestClassifier(n_estimators=200, random_state=rnd)\n",
    "xgb.fit(X_train_all, y_train_all)\n",
    "prediction = xgb.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'AdoptionSpeed': prediction.astype(int)}, index=X_test_all.index)\n",
    "submission.to_csv(\"submission.csv\", index=True, index_label='PetID', header=['AdoptionSpeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
