{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 0.10 - Description\n",
    "- Changed _tree method_ parametor to _hist_, similar method to LGBM: increased speed and slightly better CV (0.386 --> 0.390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import ml_metrics\n",
    "import string\n",
    "import nltk\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hides warnings - think it needs running after modules imported\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = 42  # random state for scoring consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/train/train.csv\", index_col=\"PetID\")\n",
    "df_test = pd.read_csv(\"../input/test/test.csv\", index_col=\"PetID\")\n",
    "df_breeds = pd.read_csv(\"../input/breed_labels.csv\", index_col=\"BreedID\")\n",
    "df_colors = pd.read_csv(\"../input/color_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = df_colors['ColorID']\n",
    "breeds = df_breeds.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tfidf Vectorizer (Better BoW technique)\n",
    "- Extracts non-stopwords from descriptions\n",
    "- Applies weighting to text depending on commonalities\n",
    "- Weight is dependent on how many other words are shared and quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer for description, to return list of word tokens\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['malibu',\n",
       " ':',\n",
       " 'femal',\n",
       " ',',\n",
       " 'local',\n",
       " 'mix',\n",
       " ',',\n",
       " '4-5',\n",
       " 'month',\n",
       " ',',\n",
       " 'vaccin',\n",
       " 'and',\n",
       " 'spay',\n",
       " '.',\n",
       " 'strike',\n",
       " 'featur',\n",
       " 'with',\n",
       " 'fade',\n",
       " 'beig',\n",
       " 'fur',\n",
       " 'and',\n",
       " 'jet-yellow',\n",
       " 'eye',\n",
       " '.',\n",
       " 'natur',\n",
       " 'curiou',\n",
       " 'explor',\n",
       " ',',\n",
       " 'immedi',\n",
       " 'taken',\n",
       " 'to',\n",
       " 'human',\n",
       " 'interact',\n",
       " 'and',\n",
       " 'love',\n",
       " 'to',\n",
       " 'play',\n",
       " 'around',\n",
       " '.',\n",
       " 'come',\n",
       " 'and',\n",
       " 'meet',\n",
       " 'our',\n",
       " 'anim',\n",
       " 'for',\n",
       " 'adopt',\n",
       " 'at',\n",
       " 'selangor',\n",
       " '(',\n",
       " 'tue',\n",
       " '-',\n",
       " 'sun',\n",
       " ',',\n",
       " '10am',\n",
       " '-',\n",
       " '4pm',\n",
       " ')',\n",
       " 'and',\n",
       " 'fall',\n",
       " 'in',\n",
       " 'love',\n",
       " '!',\n",
       " 'www.spca.org.mi']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of tokenized text\n",
    "text = df_test['Description'][3]\n",
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malibu female local mix 45 months vaccinated and spayed striking features with faded beige fur and jetyellow eyes naturally curious explorer immediately taken to human interaction and loves to play around come and meet our animals for adoption at selangor tues  sun 10am  4pm and fall in love wwwspcaorgmy\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation from text\n",
    "remove_punc = str.maketrans({key: None for key in string.punctuation})\n",
    "text = text.translate(remove_punc).lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Tfidf\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n",
    "tfs = tfidf.fit_transform([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fake entry to test\n",
    "features = tfidf.get_feature_names()\n",
    "response = tfidf.transform(['Malibu is a wonderful kitty cat who fell and was taken immediately LOVE! \\\n",
    "                             where a human without hair cared for it. Now love it needs a new home and you \\\n",
    "                             might be able to help. Please help. Call 0800-I-CARE now!!!!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taken \t 0.354\n",
      "malibu \t 0.354\n",
      "love \t 0.707\n",
      "immedi \t 0.354\n",
      "human \t 0.354\n"
     ]
    }
   ],
   "source": [
    "# output non-zero\n",
    "for col in response.nonzero()[1]:\n",
    "    print(\"{} \\t {:.3f}\".format(features[col], response[0, col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of all test data descriptions\n",
    "token_dict = {}\n",
    "for idx, desc in df_test['Description'].items():\n",
    "    try:\n",
    "        token_dict[idx] = desc.translate(remove_punc).lower()\n",
    "    except AttributeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Tfidf again\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n",
    "tfs = tfidf.fit_transform(token_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10506"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature count - 10,506 (too many??)\n",
    "features = tfidf.get_feature_names()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of all training data descriptions\n",
    "token_dict = {}\n",
    "for idx, desc in df_train['Description'].items():\n",
    "    try:\n",
    "        token_dict[idx] = desc.translate(remove_punc).lower()\n",
    "    except AttributeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Tfidf for training data\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n",
    "tfs = tfidf.fit_transform(token_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22103"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check training features count\n",
    "features_training = tfidf.get_feature_names()\n",
    "len(features_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6408"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intersecting features between test and training\n",
    "combined = set(features) & set(features_training)\n",
    "len(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPEAT: create dictionary of all test data descriptions\n",
    "token_dict = {}\n",
    "for idx, desc in df_test['Description'].items():\n",
    "    try:\n",
    "        token_dict[idx] = desc.translate(remove_punc).lower()\n",
    "    except AttributeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Tfidf for test again\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n",
    "tfs = tfidf.fit_transform(token_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and training data\n",
    "df_combined = pd.concat([df_test, df_train], sort=False)\n",
    "df_combined['test'] = df_combined['AdoptionSpeed'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10506"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check training features count\n",
    "features = tfidf.get_feature_names()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description is not text/string object\n"
     ]
    }
   ],
   "source": [
    "# ValueError where missing description is represented as np.nan (not a number - float object)\n",
    "try:\n",
    "    response = tfidf.transform(df_combined['Description'])\n",
    "except ValueError:\n",
    "    print(\"Description is not text/string object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace np.nan with blank text\n",
    "df_combined['Description'] = df_combined['Description'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all data to test data tokens\n",
    "response = tfidf.transform(df_combined['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert response to array (if becomes issue will use sparse array but might need to convert rest of data)\n",
    "response_arr = response.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18941, 10506)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tested adding this to the df but got Memory error - will need to use sparse\n",
    "response_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "3076eefcc83e005977b9159c9d39459e5d08e27a"
   },
   "outputs": [],
   "source": [
    "def apply_word_flags(df, words):\n",
    "    \"\"\"Creates binary columns for words which appear in the description\"\"\"\n",
    "    for word in words:\n",
    "        df[word] = 0\n",
    "    for i, desc in df['Description'].items():\n",
    "        try:\n",
    "            for word in desc.split():\n",
    "                word = word.lower()\n",
    "                if word in words:\n",
    "                    df.at[i,word] = 1\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    return df.drop(columns=['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['home', 'good' , 'adopt', 'loving', 'give', 'looking', 'playful', 'rescued', 'cat', 'contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_flags(df, colors):\n",
    "    \"\"\"Combines Colors 1,2 & 3 into binary columns for each possible colours\"\"\"\n",
    "    for c in colors:\n",
    "        df[f'C{c}'] = 0\n",
    "    for i,colors in df[['Color1', 'Color2', 'Color3']].iterrows():\n",
    "        for c in colors:\n",
    "            if c != 0:\n",
    "                df.at[i,f'C{c}'] = 1\n",
    "    df = df.drop(columns=['Color1', 'Color2', 'Color3'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_breed_keywords(df):\n",
    "    \"\"\"Creates unique list of keywords from provided breeds dataframe\"\"\"\n",
    "    breed_keywords = []\n",
    "    for breed in df['BreedName']:\n",
    "        breed = re.sub(r'[/(/)]', '', breed)  # remove braces\n",
    "        keywords = breed.split()\n",
    "        breed_keywords += keywords\n",
    "    return set(breed_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_breed_flags(df, keywords, breeds):\n",
    "    \"\"\"Creates binary columns for keywords which appear in the breed name\"\"\"\n",
    "    for word in keywords:\n",
    "        df[word] = 0\n",
    "        \n",
    "    for i,pair in df[['Breed1', 'Breed2']].iterrows():\n",
    "        for indx in pair:\n",
    "            if indx == 0: continue\n",
    "            breed = breeds.loc[indx,'BreedName']\n",
    "            breed = re.sub(r'[/(/)]', '', breed)\n",
    "            new_keywords = breed.split()\n",
    "            for word in new_keywords:\n",
    "                if word in keywords: \n",
    "                    df.at[i,word] = 1\n",
    "                    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and training data\n",
    "df_combined = pd.concat([df_test, df_train], sort=False)\n",
    "df_combined['test'] = df_combined['AdoptionSpeed'].isna()\n",
    "\n",
    "# Rescuer\n",
    "rescue_map = Counter(df_combined['RescuerID'])\n",
    "rescuer_counts = df_combined['RescuerID'].map(rescue_map)\n",
    "\n",
    "# Breeds\n",
    "all_test_breeds = df_test['Breed1'].append(df_test['Breed2'])\n",
    "df_test_breeds = df_breeds.loc[all_test_breeds[all_test_breeds > 0].unique(), :]\n",
    "breed_keywords = create_breed_keywords(df_test_breeds)\n",
    "\n",
    "# Prepare data for modelling \n",
    "df_combined['rescuer_counts'] = rescuer_counts\n",
    "df_combined = apply_word_flags(df_combined, keywords)\n",
    "df_combined = apply_color_flags(df_combined, colors)\n",
    "df_combined = apply_breed_flags(df_combined, breed_keywords, df_breeds)\n",
    "df_combined = pd.get_dummies(df_combined, columns=['Gender',\n",
    "                                                   'Vaccinated', 'Dewormed', 'Sterilized', \n",
    "                                                   'State'])\n",
    "y_train_all = df_combined['AdoptionSpeed'][df_combined['test'] != 1]\n",
    "X_all       = df_combined.drop(columns=['Name', 'RescuerID', 'AdoptionSpeed', 'Breed1', 'Breed2'])\n",
    "X_train_all = X_all[X_all['test'] != 1].drop(columns=['test'])\n",
    "X_test_all  = X_all[X_all['test'] == 1].drop(columns=['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with sparse data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  2, ...,  0,  0,  0],\n",
       "       [ 2, 24,  2, ...,  0,  0,  0],\n",
       "       [ 2, 20,  2, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 2,  2,  3, ...,  0,  0,  0],\n",
       "       [ 2,  9,  1, ...,  0,  0,  0],\n",
       "       [ 1,  1,  2, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert all data to numpy and convert to integers (scipy doesn't like mixed data types)\n",
    "X_all_values = np.array(X_all.values.astype(int))\n",
    "X_all_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all data to sparse data array\n",
    "X_all_sparse = scipy.sparse.csr_matrix(np.array(X_all.values.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas DataFrame:(18941, 215)\n",
      "Sparse Array: \t (18941, 215)\n"
     ]
    }
   ],
   "source": [
    "# shape of sparse array, compared to pandas dataframe\n",
    "print(f\"Pandas DataFrame:{X_all.shape}\")\n",
    "print(f\"Sparse Array: \\t {X_all_sparse.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index of test column\n",
    "list(X_all.columns).index('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Indexing with sparse matrices is not supported except boolean indexing where matrix and index are equal shapes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-020ff9f2b69b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# split all data into test and training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_all_sparse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_all_sparse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    280\u001b[0m                               dtype=self.dtype, copy=False)\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# First attempt to use original row optimized methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36m_unpack_index\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Next, check for validity, or transform the index as needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36m_check_boolean\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             raise IndexError(\n\u001b[0;32m--> 427\u001b[0;31m                 \u001b[0;34m\"Indexing with sparse matrices is not supported \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m                 \u001b[0;34m\"except boolean indexing where matrix and index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \"are equal shapes.\")\n",
      "\u001b[0;31mIndexError\u001b[0m: Indexing with sparse matrices is not supported except boolean indexing where matrix and index are equal shapes."
     ]
    }
   ],
   "source": [
    "# split all data into test and training\n",
    "mask = X_all_sparse[:,9]\n",
    "X_all_sparse[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 4, \n",
    "          'learning_rate': 0.2, \n",
    "          'n_estimators': 200, \n",
    "          'silent': True, \n",
    "          'objective': 'multi:softprob', \n",
    "          'booster': 'gbtree',\n",
    "          'tree_method': 'hist',\n",
    "          'n_jobs': 3,\n",
    "          'gamma': 0, \n",
    "          'min_child_weight': 1, \n",
    "          'max_delta_step': 0, \n",
    "          'subsample': 0.8, \n",
    "          'colsample_bytree': 1, \n",
    "          'colsample_bylevel': 1, \n",
    "          'reg_alpha': 0, \n",
    "          'reg_lambda': 1, \n",
    "          'scale_pos_weight': 1, \n",
    "          'base_score': 0.2, \n",
    "          'random_state': rnd, \n",
    "          'missing': None,\n",
    "          'verbose': 0,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cv_testing(X_train_all, params, folds=5):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    folds = KFold(folds, True, rnd).split(X_train_all)\n",
    "\n",
    "    for train_indx, test_indx in folds:\n",
    "\n",
    "        X_train, X_test = X_train_all.iloc[train_indx], X_train_all.iloc[test_indx]\n",
    "        y_train, y_test = y_train_all.iloc[train_indx], y_train_all.iloc[test_indx]\n",
    "\n",
    "\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        prediction = clf.predict(X_test)\n",
    "\n",
    "        scores.append(ml_metrics.quadratic_weighted_kappa(rater_a=y_test, rater_b=prediction))\n",
    "        print(\"{:.3f}\".format(scores[-1]), end=\"\\t\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:34:08] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.394\t[21:34:15] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "0.436\t[21:34:23] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-28f1e738c994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-6f7f4dee97a1>\u001b[0m in \u001b[0;36mcv_testing\u001b[0;34m(X_train_all, params, folds)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    698\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1045\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = cv_testing(X_train_all=X_train_all, folds=10, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3909419241621025"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.386 --> 0.390 (changed tree method to 'hist')\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(**params)\n",
    "clf.fit(X_train_all, y_train_all)\n",
    "prediction = clf.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'AdoptionSpeed': prediction.astype(int)}, index=X_test_all.index)\n",
    "submission.to_csv(\"submission.csv\", index=True, index_label='PetID', header=['AdoptionSpeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
